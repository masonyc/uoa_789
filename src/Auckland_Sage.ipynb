{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import calendar\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.loader import NeighborSampler as RawNeighborSampler\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# output_path = \"/run/media/yunchen/lacie\"\n",
    "#dataset_path = \"./datasets/prewalk/with_amenity_filters\"\n",
    "dataset_path = \"./datasets/prewalk/without_amenity_filters\"\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "HIDDEN_LAYER = 16\n",
    "NUM_LAYERS = 10\n",
    "NEIGHBOUR_SIZE = [5,5]\n",
    "DROP_OUT = 0.5\n",
    "BATCH_SIZE = 256\n",
    "DISTANCE_PENALTY_LAYER = 5\n",
    "SHUFFLE = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           distance\n",
      "count  1.004718e+06\n",
      "mean   3.779548e-02\n",
      "std    4.296331e-02\n",
      "min    1.736350e-04\n",
      "25%    1.300390e-02\n",
      "50%    2.492522e-02\n",
      "75%    4.658313e-02\n",
      "max    4.629630e+00\n",
      "tensor([[     0,      2,      0,  ..., 458250, 458250, 458251],\n",
      "        [     2,      0,      1,  ..., 458249, 458251, 458250]])\n",
      "tensor([0.0103, 0.0103, 0.0099,  ..., 0.0030, 0.0020, 0.0020])\n"
     ]
    }
   ],
   "source": [
    "street_nodes_df = pd.read_csv(f\"{dataset_path}/akl_prewalked_nodes.csv\")\n",
    "street_edges_df = pd.read_csv(f\"{dataset_path}/akl_street_edges.csv\")\n",
    "\n",
    "# 求倒数\n",
    "# street_edges_df[['distance']] = np.where(street_edges_df[['distance']]<=300 , 300, street_edges_df[['distance']])\n",
    "\n",
    "street_edges_df[['distance']] = street_edges_df[['distance']].rdiv(1)\n",
    "print(street_edges_df[['distance']].describe())\n",
    "# scaler = MinMaxScaler()\n",
    "# street_edges_df[['distance']] = scaler.fit_transform(street_edges_df[['distance']])\n",
    "\n",
    "source_street_index, targe_street_index, street_distance_weight = street_edges_df[\"source_street\"], street_edges_df[\n",
    "    \"target_street\"], street_edges_df[\"distance\"]\n",
    "\n",
    "# isolated_list = []\n",
    "# non_isolated_source = set(source_street_index.values.tolist())\n",
    "# non_isolated_target = set(targe_street_index.values.tolist())\n",
    "# for isolated_i,_ in street_nodes_df.iterrows():\n",
    "#     if isolated_i not in non_isolated_source and isolated_i  not in non_isolated_target:\n",
    "#         isolated_list.append(isolated_i)\n",
    "# street_nodes_df.drop(axis=0,index = isolated_list,inplace=True)\n",
    "\n",
    "street_edges_source_index_tensor = torch.tensor([source_street_index.values.tolist()])\n",
    "street_edges_target_index_tensor = torch.tensor([targe_street_index.values.tolist()])\n",
    "street_edges_index_tensor = torch.cat((street_edges_source_index_tensor, street_edges_target_index_tensor), 0)\n",
    "street_edges_weight_tensor = torch.tensor(street_distance_weight.values.tolist())\n",
    "\n",
    "print(street_edges_index_tensor)\n",
    "print(street_edges_weight_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 Positive POI 16148  Negative POI 442104\n",
      "Layer 1 Positive POI 30711  Negative POI 427541\n",
      "Layer 2 Positive POI 52050  Negative POI 406202\n",
      "Layer 3 Positive POI 70259  Negative POI 387993\n",
      "Layer 4 Positive POI 86345  Negative POI 371907\n",
      "Layer 5 Positive POI 100598  Negative POI 357654\n"
     ]
    }
   ],
   "source": [
    "count_poi_df = street_nodes_df.copy()\n",
    "#count_poi_df[\"poi_count\"] = count_poi_df.apply(lambda row:row.amenity+row.restaurant+row.education+row.healthcare+row.shop+row.cloth,axis=1)\n",
    "count_poi_df[\"poi_count\"] = count_poi_df.apply(lambda row:row.amenity+row.restaurant+row.school+row.healthcare+row.shop+row.clothes,axis=1)\n",
    "positive_nodes_with_poi_df_layer0 = count_poi_df[count_poi_df[\"poi_count\"]>0]\n",
    "negative_nodes_without_poi_df_layer0 = count_poi_df[count_poi_df[\"poi_count\"]<=0]\n",
    "positive_nodes_with_poi_df_layer1 = count_poi_df[count_poi_df[\"Layer_1_agg_poi_count\"]>0]\n",
    "negative_nodes_without_poi_df_layer1 = count_poi_df[count_poi_df[\"Layer_1_agg_poi_count\"]<=0]\n",
    "positive_nodes_with_poi_df_layer2 = count_poi_df[count_poi_df[\"Layer_2_agg_poi_count\"]>0]\n",
    "negative_nodes_without_poi_df_layer2 = count_poi_df[count_poi_df[\"Layer_2_agg_poi_count\"]<=0]\n",
    "positive_nodes_with_poi_df_layer3 = count_poi_df[count_poi_df[\"Layer_3_agg_poi_count\"]>0]\n",
    "negative_nodes_without_poi_df_layer3 = count_poi_df[count_poi_df[\"Layer_3_agg_poi_count\"]<=0]\n",
    "positive_nodes_with_poi_df_layer4 = count_poi_df[count_poi_df[\"Layer_4_agg_poi_count\"]>0]\n",
    "negative_nodes_without_poi_df_layer4 = count_poi_df[count_poi_df[\"Layer_4_agg_poi_count\"]<=0]\n",
    "positive_nodes_with_poi_df_layer5 = count_poi_df[count_poi_df[\"Layer_5_agg_poi_count\"]>0]\n",
    "negative_nodes_without_poi_df_layer5 = count_poi_df[count_poi_df[\"Layer_5_agg_poi_count\"]<=0]\n",
    "print(f\"Layer 0 Positive POI {len(positive_nodes_with_poi_df_layer0)}  Negative POI {len(negative_nodes_without_poi_df_layer0)}\")\n",
    "print(f\"Layer 1 Positive POI {len(positive_nodes_with_poi_df_layer1)}  Negative POI {len(negative_nodes_without_poi_df_layer1)}\")\n",
    "print(f\"Layer 2 Positive POI {len(positive_nodes_with_poi_df_layer2)}  Negative POI {len(negative_nodes_without_poi_df_layer2)}\")\n",
    "print(f\"Layer 3 Positive POI {len(positive_nodes_with_poi_df_layer3)}  Negative POI {len(negative_nodes_without_poi_df_layer3)}\")\n",
    "print(f\"Layer 4 Positive POI {len(positive_nodes_with_poi_df_layer4)}  Negative POI {len(negative_nodes_without_poi_df_layer4)}\")\n",
    "print(f\"Layer 5 Positive POI {len(positive_nodes_with_poi_df_layer5)}  Negative POI {len(negative_nodes_without_poi_df_layer5)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['restaurant', 'amenity', 'school', 'healthcare', 'shop', 'clothes',\n",
      "       'Average_POI_Distance', 'Layer_1_agg_restaurant', 'Layer_1_agg_amenity',\n",
      "       'Layer_1_agg_school', 'Layer_1_agg_healthcare', 'Layer_1_agg_shop',\n",
      "       'Layer_1_agg_clothes', 'Layer_1_agg_average_poi_distance',\n",
      "       'Layer_2_agg_restaurant', 'Layer_2_agg_amenity', 'Layer_2_agg_school',\n",
      "       'Layer_2_agg_healthcare', 'Layer_2_agg_shop', 'Layer_2_agg_clothes',\n",
      "       'Layer_2_agg_average_poi_distance', 'Layer_3_agg_restaurant',\n",
      "       'Layer_3_agg_amenity', 'Layer_3_agg_school', 'Layer_3_agg_healthcare',\n",
      "       'Layer_3_agg_shop', 'Layer_3_agg_clothes',\n",
      "       'Layer_3_agg_average_poi_distance', 'Layer_4_agg_restaurant',\n",
      "       'Layer_4_agg_amenity', 'Layer_4_agg_school', 'Layer_4_agg_healthcare',\n",
      "       'Layer_4_agg_shop', 'Layer_4_agg_clothes',\n",
      "       'Layer_4_agg_average_poi_distance', 'Layer_5_agg_restaurant',\n",
      "       'Layer_5_agg_amenity', 'Layer_5_agg_school', 'Layer_5_agg_healthcare',\n",
      "       'Layer_5_agg_shop', 'Layer_5_agg_clothes',\n",
      "       'Layer_5_agg_average_poi_distance'],\n",
      "      dtype='object')\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0207],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0262],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0136],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0236],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0273],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0239]],\n",
      "       dtype=torch.float64)\n",
      "458252\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "street_nodes_df_copy = street_nodes_df.copy()\n",
    "# street_nodes_df_copy = street_nodes_df_copy[[\"Layer_5_agg_restaurant\", \"Layer_5_agg_amenity\",\"Layer_5_agg_education\",\"Layer_5_agg_healthcare\",\"Layer_5_agg_shop\",\"Layer_5_agg_cloth\",\"Layer_5_agg_average_poi_distance\"]]\n",
    "#street_nodes_df_copy = street_nodes_df_copy[[\"restaurant\",\"amenity\",\"education\",\"healthcare\",\"shop\",\"cloth\",\"Average_POI_Distance\",\"Layer_1_agg_restaurant\", \"Layer_1_agg_amenity\",\"Layer_1_agg_education\",\"Layer_1_agg_healthcare\",\"Layer_1_agg_shop\",\"Layer_1_agg_cloth\",\"Layer_1_agg_average_poi_distance\",\"Layer_2_agg_restaurant\", \"Layer_2_agg_amenity\",\"Layer_2_agg_education\",\"Layer_2_agg_healthcare\",\"Layer_2_agg_shop\",\"Layer_2_agg_cloth\",\"Layer_2_agg_average_poi_distance\",\"Layer_3_agg_restaurant\", \"Layer_3_agg_amenity\",\"Layer_3_agg_education\",\"Layer_3_agg_healthcare\",\"Layer_3_agg_shop\",\"Layer_3_agg_cloth\",\"Layer_3_agg_average_poi_distance\",\"Layer_4_agg_restaurant\", \"Layer_4_agg_amenity\",\"Layer_4_agg_education\",\"Layer_4_agg_healthcare\",\"Layer_4_agg_shop\",\"Layer_4_agg_cloth\",\"Layer_4_agg_average_poi_distance\",\"Layer_5_agg_restaurant\", \"Layer_5_agg_amenity\",\"Layer_5_agg_education\",\"Layer_5_agg_healthcare\",\"Layer_5_agg_shop\",\"Layer_5_agg_cloth\",\"Layer_5_agg_average_poi_distance\",]]\n",
    "\n",
    "#street_nodes_df_copy = street_nodes_df_copy[[\"restaurant\", \"amenity\",\"school\",\"healthcare\",\"shop\",\"clothes\"]]\n",
    "#street_nodes_df_copy = street_nodes_df_copy[[\"Layer_5_agg_restaurant\", \"Layer_5_agg_amenity\",\"Layer_5_agg_school\",\"Layer_5_agg_healthcare\",\"Layer_5_agg_shop\",\"Layer_5_agg_clothes\"]]#,\"Layer_5_agg_average_poi_distance\"]]\n",
    "street_nodes_df_copy = street_nodes_df_copy[[\"restaurant\",\"amenity\",\"school\",\"healthcare\",\"shop\",\"clothes\",\"Average_POI_Distance\",\"Layer_1_agg_restaurant\", \"Layer_1_agg_amenity\",\"Layer_1_agg_school\",\"Layer_1_agg_healthcare\",\"Layer_1_agg_shop\",\"Layer_1_agg_clothes\",\"Layer_1_agg_average_poi_distance\",\"Layer_2_agg_restaurant\", \"Layer_2_agg_amenity\",\"Layer_2_agg_school\",\"Layer_2_agg_healthcare\",\"Layer_2_agg_shop\",\"Layer_2_agg_clothes\",\"Layer_2_agg_average_poi_distance\",\"Layer_3_agg_restaurant\", \"Layer_3_agg_amenity\",\"Layer_3_agg_school\",\"Layer_3_agg_healthcare\",\"Layer_3_agg_shop\",\"Layer_3_agg_clothes\",\"Layer_3_agg_average_poi_distance\",\"Layer_4_agg_restaurant\", \"Layer_4_agg_amenity\",\"Layer_4_agg_school\",\"Layer_4_agg_healthcare\",\"Layer_4_agg_shop\",\"Layer_4_agg_clothes\",\"Layer_4_agg_average_poi_distance\",\"Layer_5_agg_restaurant\", \"Layer_5_agg_amenity\",\"Layer_5_agg_school\",\"Layer_5_agg_healthcare\",\"Layer_5_agg_shop\",\"Layer_5_agg_clothes\",\"Layer_5_agg_average_poi_distance\",]]\n",
    "print(street_nodes_df_copy.columns)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "street_nodes_df_transformed = scaler.fit_transform(street_nodes_df_copy)\n",
    "street_nodes_features_tensor = torch.tensor(street_nodes_df_transformed)\n",
    "\n",
    "number_of_nodes = len(street_nodes_features_tensor)\n",
    "number_of_node_features = len(street_nodes_features_tensor[0])\n",
    "print(street_nodes_features_tensor)\n",
    "print(number_of_nodes)\n",
    "print(number_of_node_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# street_nodes_df = street_nodes_df[street_nodes_df.columns[4:]]\n",
    "#\n",
    "# street_nodes_df_copy = street_nodes_df.copy()\n",
    "# print(street_nodes_df_copy.head)\n",
    "# # street_nodes_df_copy.drop([\"street_length\", \"Average_POI_Distance\",\"x\",\"y\"], axis=1, inplace=True)\n",
    "# street_nodes_df_copy.drop([\"street_length\",\"Average_POI_Distance\"], axis=1, inplace=True)\n",
    "# print(street_nodes_df_copy.columns)\n",
    "#\n",
    "# street_nodes_features_tensor = torch.tensor(street_nodes_df_copy.values.tolist())\n",
    "#\n",
    "# number_of_nodes = len(street_nodes_features_tensor)\n",
    "# number_of_node_features = len(street_nodes_features_tensor[0])\n",
    "# print(street_nodes_features_tensor)\n",
    "# print(number_of_nodes)\n",
    "# print(number_of_node_features)\n",
    "#\n",
    "# street_nodes_df_copy_2 = street_nodes_df.copy()\n",
    "# # street_nodes_df_copy_2[\"poi_count\"] = street_nodes_df_copy_2.apply(lambda row:row.amenity+row.restaurant+row.school+row.shop+row.healthcare+row.clothes,axis=1)\n",
    "# street_nodes_df_copy_2[\"poi_count\"] = street_nodes_df_copy_2.apply(lambda row:row.amenity+row.restaurant+row.education+row.healthcare+row.shop+row.cloth,axis=1)\n",
    "# positive_nodes_with_poi_df_layer = street_nodes_df_copy_2[street_nodes_df_copy_2[\"poi_count\"]>0]\n",
    "# negative_nodes_without_poi_df_layer = street_nodes_df_copy_2[street_nodes_df_copy_2[\"poi_count\"]<=0]\n",
    "# positive_nodes_index = torch.tensor(positive_nodes_with_poi_df.index)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# def custom_pos_sampling_with_POI(\n",
    "#         edge_weight: Tensor,\n",
    "#         batch: Tensor,\n",
    "# ):\n",
    "#     pos_node_seq = []\n",
    "#     neg_node_seq = []\n",
    "#     for start_node_id in batch:\n",
    "#         current_node_seq = [start_node_id.item()]\n",
    "#         current_node_id = current_node_seq[-1]\n",
    "#\n",
    "#         neighbours_edge_index = (street_edges_index_tensor == current_node_id).nonzero(as_tuple=True)[1]\n",
    "#         len_neighbours_edge_index = len(neighbours_edge_index)\n",
    "#         neighbour_id_list = []\n",
    "#         for i in neighbours_edge_index:\n",
    "#             neighbour_id_list.append(select_neighbour_node_id_from_edge(i,current_node_id))\n",
    "#\n",
    "#         normalized_neighbour_poi_weights = calculate_normalized_poi_weights(neighbour_id_list)\n",
    "#\n",
    "#         global_node_without_poi = negative_nodes_without_poi_df.sample(replace=True).index.values[0]\n",
    "#         global_node_with_poi = positive_nodes_with_poi_df.sample(n=1,replace=True).index.values[0]\n",
    "#         # all neighbours don't have POI\n",
    "#         if np.isnan(normalized_neighbour_poi_weights).all():\n",
    "#             # Also no neighbour\n",
    "#             if len_neighbours_edge_index == 0:\n",
    "#                 pos_node_seq.append([current_node_id,global_node_without_poi])\n",
    "#                 neg_node_seq.append(global_node_with_poi)\n",
    "#                 # neg_node_seq.append(current_node_id)\n",
    "#                 # pos_node_seq.append([global_node_with_poi,global_node_with_poi])\n",
    "#                 continue\n",
    "#             # No neighbour has POIs but do have neighbours\n",
    "#             else:\n",
    "#                 # Pick a neighbour randomly using distance distribution to give future poi opportunity\n",
    "#                 neighbour_distance_weights = torch.index_select(edge_weight, 0, neighbours_edge_index).numpy()\n",
    "#                 norm_neighbour_distance_weights = calculate_normalized_distance_weights(neighbour_distance_weights)\n",
    "#                 neighbour_weights_index = np.random.choice(len(norm_neighbour_distance_weights),p=norm_neighbour_distance_weights)\n",
    "#\n",
    "#                 pos_node_seq.append([current_node_id,global_node_without_poi])\n",
    "#                 neg_node_seq.append(global_node_with_poi)\n",
    "#                 continue\n",
    "#         # normal case pick with poi distribution\n",
    "#         else:\n",
    "#             neighbour_weights_index = np.random.choice(len(normalized_neighbour_poi_weights),\n",
    "#                                                        p=normalized_neighbour_poi_weights)\n",
    "#\n",
    "#         next_edge_index = neighbours_edge_index[neighbour_weights_index]\n",
    "#         next_node_id = select_neighbour_node_id_from_edge(next_edge_index,current_node_id)\n",
    "#\n",
    "#         pos_node_seq.append([current_node_id,next_node_id])\n",
    "#         neg_node_seq.append(global_node_without_poi)\n",
    "#\n",
    "#     return torch.from_numpy(np.asarray(pos_node_seq, dtype=np.int32))[:, 1], torch.from_numpy(\n",
    "#         np.asarray(neg_node_seq, dtype=np.int32))\n",
    "#\n",
    "# def calculate_normalized_distance_weights(neighbour_distance_weights):\n",
    "#     neighbour_distance_weights_sum = sum(neighbour_distance_weights)\n",
    "#     reverted_norm_neighbour_distance_weights = [1-(i / neighbour_distance_weights_sum) for i in neighbour_distance_weights]\n",
    "#\n",
    "#     reverted_norm_neighbour_distance_weights_sum = sum(reverted_norm_neighbour_distance_weights)\n",
    "#     norm_neighbour_distance_weights = [(i / reverted_norm_neighbour_distance_weights_sum) for i in reverted_norm_neighbour_distance_weights]\n",
    "#     return norm_neighbour_distance_weights\n",
    "#\n",
    "# def calculate_normalized_poi_weights(neighbour_id_list):\n",
    "#     neighbour_id_weights = []\n",
    "#     for neighbour_id in neighbour_id_list:\n",
    "#         poi_weight = 0\n",
    "#         neighbour_features = torch.index_select(street_nodes_features_tensor, 0,\n",
    "#                                                 torch.tensor(int(neighbour_id), dtype=torch.int32))\n",
    "#         poi_weight += torch.sum(neighbour_features)\n",
    "#         neighbour_id_weights.append(poi_weight)\n",
    "#\n",
    "#     neighbour_poi_weights = np.array(neighbour_id_weights)\n",
    "#     neighbour_poi_weights_sum=sum(neighbour_poi_weights)\n",
    "#     normalized_neighbour_poi_weights = [i / neighbour_poi_weights_sum for i in neighbour_poi_weights]\n",
    "#     return normalized_neighbour_poi_weights\n",
    "#\n",
    "# def select_neighbour_node_id_from_edge(next_edge_index,current_node_id):\n",
    "#     next_edge_df = street_edges_df.iloc[[next_edge_index]]\n",
    "#     next_edge = next_edge_df.values[0]\n",
    "#     if next_edge[0] != current_node_id:\n",
    "#         neighbour_node_id = next_edge[0]\n",
    "#     else:\n",
    "#         neighbour_node_id = next_edge[1]\n",
    "#\n",
    "#     return neighbour_node_id\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def custom_sampling_with_Prewalk(\n",
    "        edge_weight: Tensor,\n",
    "        batch: Tensor,\n",
    "):\n",
    "    pos_node_seq = []\n",
    "    neg_node_seq = []\n",
    "    for start_node_id in batch:\n",
    "        current_node_seq = [start_node_id.item()]\n",
    "        current_node_id = current_node_seq[-1]\n",
    "\n",
    "        neighbours_edge_index = (street_edges_index_tensor == current_node_id).nonzero(as_tuple=True)[1]\n",
    "        neighbour_id_list = []\n",
    "        for i in neighbours_edge_index:\n",
    "            neighbour_id_list.append(select_neighbour_node_id_from_edge(i,current_node_id))\n",
    "\n",
    "        normalized_neighbour_poi_weights = calculate_normalized_poi_weights(neighbour_id_list)\n",
    "\n",
    "        global_node_without_poi_layer5 = negative_nodes_without_poi_df_layer5.sample(replace=True).index.values[0]\n",
    "        global_node_with_poi_layer5 = positive_nodes_with_poi_df_layer5.sample(replace=True).index.values[0]\n",
    "        # all neighbours don't have POI\n",
    "        if np.isnan(normalized_neighbour_poi_weights).all():\n",
    "            pos_node_seq.append([current_node_id,global_node_without_poi_layer5])\n",
    "            neg_node_seq.append(global_node_with_poi_layer5)\n",
    "            continue\n",
    "        # normal case pick with poi distribution\n",
    "        else:\n",
    "            neighbour_weights_index = np.random.choice(len(normalized_neighbour_poi_weights),\n",
    "                                                       p=normalized_neighbour_poi_weights)\n",
    "\n",
    "        next_edge_index = neighbours_edge_index[neighbour_weights_index]\n",
    "        next_node_id = select_neighbour_node_id_from_edge(next_edge_index,current_node_id)\n",
    "\n",
    "        pos_node_seq.append([current_node_id,next_node_id])\n",
    "        neg_node_seq.append(global_node_without_poi_layer5)\n",
    "\n",
    "    return torch.from_numpy(np.asarray(pos_node_seq, dtype=np.int32))[:, 1], torch.from_numpy(\n",
    "        np.asarray(neg_node_seq, dtype=np.int32))\n",
    "\n",
    "def calculate_normalized_poi_weights(neighbour_id_list):\n",
    "    neighbour_id_weights = []\n",
    "    for neighbour_id in neighbour_id_list:\n",
    "        poi_weight = 0\n",
    "        neighbour_features = torch.index_select(street_nodes_features_tensor, 0,\n",
    "                                                torch.tensor(int(neighbour_id), dtype=torch.int32))\n",
    "        neighbour_features = neighbour_features[0][len(neighbour_features)-6:]\n",
    "\n",
    "        poi_weight += torch.sum(neighbour_features)\n",
    "        neighbour_id_weights.append(poi_weight)\n",
    "\n",
    "    neighbour_poi_weights = np.array(neighbour_id_weights)\n",
    "    neighbour_poi_weights_sum=sum(neighbour_poi_weights)\n",
    "    normalized_neighbour_poi_weights = [i / neighbour_poi_weights_sum for i in neighbour_poi_weights]\n",
    "    return normalized_neighbour_poi_weights\n",
    "\n",
    "def select_neighbour_node_id_from_edge(next_edge_index,current_node_id):\n",
    "    next_edge_df = street_edges_df.iloc[[next_edge_index]]\n",
    "    next_edge = next_edge_df.values[0]\n",
    "    if next_edge[0] != current_node_id:\n",
    "        neighbour_node_id = next_edge[0]\n",
    "    else:\n",
    "        neighbour_node_id = next_edge[1]\n",
    "\n",
    "    return neighbour_node_id\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RawNeighborSampler This module iteratively samples neighbors (at each layer) and constructs bipartite graphs that simulate the actual computation flow of GNNs.\n",
    "\n",
    "format-selected)\n",
    "NeighborSampler holds the current :obj:batch_size, the IDs :obj:n_id of all nodes involved in the computation, and a list of bipartite graph objects via the tuple :obj:(edge_index, e_id, size), where :obj:edge_index represents the bipartite edges between source and target nodes, :obj:e_id denotes the IDs of original edges in the full graph, and :obj:size holds the shape of the bipartite graph.\n",
    "\n",
    "The actual computation graphs are then returned in reverse-mode, meaning that we pass messages from a larger set of nodes to a smaller one, until we reach the nodes for which we originally wanted to compute embeddings.\n",
    "https://www.arangodb.com/2021/08/a-comprehensive-case-study-of-graphsage-using-pytorchgeometric/\n",
    "https://towardsdatascience.com/pytorch-geometric-graph-embedding-da71d614c3a\n",
    "https://gist.github.com/anuradhawick/904e7f2d2101f4b76516d04046007426\n",
    "https://zhuanlan.zhihu.com/p/387262710\n",
    "\"\"\"\n",
    "\n",
    "class NeighborSampler(RawNeighborSampler):\n",
    "    def sample(self, batch):\n",
    "        batch = torch.tensor(batch)\n",
    "\n",
    "        pos_batch, neg_batch = custom_sampling_with_Prewalk(street_edges_weight_tensor, batch)\n",
    "        batch = torch.cat([batch, pos_batch, neg_batch], dim=0)\n",
    "        return super(NeighborSampler,self).sample(batch)\n",
    "\n",
    "train_loader = NeighborSampler(street_edges_index_tensor, sizes=NEIGHBOUR_SIZE, batch_size=BATCH_SIZE, num_nodes=number_of_nodes,shuffle=SHUFFLE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn import LSTM\n",
    "\n",
    "from torch_geometric.nn.aggr import Aggregation, MultiAggregation\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.typing import Adj, OptPairTensor,OptTensor, Size\n",
    "\n",
    "\n",
    "class CustomSAGEConv(MessagePassing):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Tuple[int, int]],\n",
    "        out_channels: int,\n",
    "        aggr: Optional[Union[str, List[str], Aggregation]] = \"mean\",\n",
    "        normalize: bool = False,\n",
    "        root_weight: bool = True,\n",
    "        project: bool = False,\n",
    "        bias: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "        self.root_weight = root_weight\n",
    "        self.project = project\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        if aggr == 'lstm':\n",
    "            kwargs.setdefault('aggr_kwargs', {})\n",
    "            kwargs['aggr_kwargs'].setdefault('in_channels', in_channels[0])\n",
    "            kwargs['aggr_kwargs'].setdefault('out_channels', in_channels[0])\n",
    "\n",
    "        super().__init__(aggr, **kwargs)\n",
    "\n",
    "        if self.project:\n",
    "            self.lin = Linear(in_channels[0], in_channels[0], bias=True)\n",
    "\n",
    "        if self.aggr is None:\n",
    "            self.fuse = False  # No \"fused\" message_and_aggregate.\n",
    "            self.lstm = LSTM(in_channels[0], in_channels[0], batch_first=True)\n",
    "\n",
    "        if isinstance(self.aggr_module, MultiAggregation):\n",
    "            aggr_out_channels = self.aggr_module.get_out_channels(\n",
    "                in_channels[0])\n",
    "        else:\n",
    "            aggr_out_channels = in_channels[0]\n",
    "\n",
    "        self.lin_l = Linear(aggr_out_channels, out_channels, bias=bias)\n",
    "        if self.root_weight:\n",
    "            self.lin_r = Linear(in_channels[1], out_channels, bias=False)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.project:\n",
    "            self.lin.reset_parameters()\n",
    "        self.aggr_module.reset_parameters()\n",
    "        self.lin_l.reset_parameters()\n",
    "        if self.root_weight:\n",
    "            self.lin_r.reset_parameters()\n",
    "\n",
    "    def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj,\n",
    "                size: Size = None,edge_weight: OptTensor=None) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        if isinstance(x, Tensor):\n",
    "            x: OptPairTensor = (x, x)\n",
    "\n",
    "        if self.project and hasattr(self, 'lin'):\n",
    "            x = (self.lin(x[0]).relu(), x[1])\n",
    "\n",
    "        # propagate_type: (x: OptPairTensor)\n",
    "        edge_weight: OptTensor = edge_weight\n",
    "        out = self.propagate(edge_index, x=x, size=size,edge_weight=edge_weight)\n",
    "        out = self.lin_l(out)\n",
    "\n",
    "        x_r = x[1]\n",
    "        if self.root_weight and x_r is not None:\n",
    "            out = out + self.lin_r(x_r)\n",
    "\n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2., dim=-1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j: Tensor, edge_weight: OptTensor) -> Tensor:\n",
    "        #print(f\"In Message Edge Weight {edge_weight}\")\n",
    "        #print(f\"In Message Edge Weight view  {edge_weight.view(-1, 1)}\")\n",
    "        #print(f\"In Message x_j  {x_j}\")\n",
    "        #print(f\"In Message {edge_weight.view(-1, 1) * x_j}\")\n",
    "        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, aggr={self.aggr})')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_layers):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_channels = in_channels if i == 0 else hidden_channels\n",
    "            self.convs.append(CustomSAGEConv(in_channels, hidden_channels))\n",
    "\n",
    "    def forward(self, x, adjs):\n",
    "        for i, (edge_index, edge_id, size) in enumerate(adjs):\n",
    "            copy_edge_weight = street_edges_weight_tensor.clone()\n",
    "            nn_edge_weight =copy_edge_weight[edge_id].to(device)\n",
    "            x_target = x[:size[1]]  # Target nodes are always placed first.\n",
    "\n",
    "            if i > DISTANCE_PENALTY_LAYER:\n",
    "                x = self.convs[i]((x, x_target), edge_index, edge_weight = nn_edge_weight)\n",
    "            else:\n",
    "                x = self.convs[i]((x, x_target), edge_index)\n",
    "\n",
    "            if i != self.num_layers - 1:\n",
    "                x = x.relu()\n",
    "                x = F.dropout(x, p=DROP_OUT, training=self.training)\n",
    "        return x\n",
    "\n",
    "    def full_forward(self, x, edge_index,fn_edge_weight):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i != self.num_layers - 1:\n",
    "                x = x.relu()\n",
    "                x = F.dropout(x, p=DROP_OUT, training=self.training)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = SAGE(number_of_node_features, hidden_channels=HIDDEN_LAYER, num_layers=NUM_LAYERS)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "edge_weight_tensor = street_edges_weight_tensor.clone()\n",
    "x, edge_index,edge_weight = street_nodes_features_tensor.to(device), street_edges_index_tensor.to(device),edge_weight_tensor.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def regression_train(embedding_df):\n",
    "    AKL_df = pd.read_csv(f\"{dataset_path}/property_data_with_street.csv\", encoding='latin1')\n",
    "    AKL_df = AKL_df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "    akl_embedding_np = embedding_df.numpy()  #convert to Numpy array\n",
    "    akl_embedding_df = pd.DataFrame(akl_embedding_np)  #convert to a dataframe\n",
    "    embedding_size = akl_embedding_df.shape[1]\n",
    "    akl_embedding_df.columns = ['street_embedding_' + str(i) for i in range(embedding_size)]\n",
    "\n",
    "    akl_street_nodes_df = pd.read_csv(f\"{dataset_path}/akl_prewalked_nodes.csv\")\n",
    "    akl_street_nodes_df = akl_street_nodes_df.rename(columns={\"source\": \"street_sources\", \"target\": \"street_targets\"})\n",
    "    AKL_df = find_embedding_for_property(AKL_df, akl_street_nodes_df, akl_embedding_df)\n",
    "    property_columns = ['CL_Suburb', 'CL_Sale_Tenure', 'CL_Sale_Date', 'CL_Land_Valuation_Capital_Value',\n",
    "                        'CL_Building_Floor_Area', 'CL_Building_Site_Cover',\n",
    "                        'CL_Land_Area', 'CL_Bldg_Const', 'CL_Bldg_Cond', 'CL_Roof_Const', 'CL_Roof_Cond',\n",
    "                        'CL_Category', 'CL_LUD_Age', 'CL_LUD_Land_Use_Description',\n",
    "                        'CL_MAS_No_Main_Roof_Garages', 'CL_Bedrooms', 'CL_Bathrooms'] + ['street_embedding_' + str(i)\n",
    "                                                                                         for i in range(embedding_size)]\n",
    "    X_columns = AKL_df[property_columns].values\n",
    "    #print(X_columns)\n",
    "    Y_column = AKL_df['Log_Sale_Price_Net'].values\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_columns, Y_column, test_size=0.2, random_state=1,\n",
    "                                                        shuffle=True)\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=1, shuffle=True)\n",
    "    hedonic_regression = LinearRegression()\n",
    "    hedonic_regression.fit(X_train, Y_train)\n",
    "\n",
    "    hedonic_regression_validation_result = hedonic_regression.predict(X_val)\n",
    "\n",
    "    validation_RMSE = round(mean_squared_error(Y_val, hedonic_regression_validation_result), 4)\n",
    "    validation_R2 = round(r2_score(Y_val, hedonic_regression_validation_result), 4)\n",
    "    return validation_RMSE, validation_R2\n",
    "\n",
    "\n",
    "def find_embedding_for_property(property_df, street_df, emb_df):\n",
    "    street_with_embedding = street_df.merge(emb_df, left_index=True, right_index=True)\n",
    "    output_df = property_df.merge(street_with_embedding, on=[\"street_sources\", \"street_targets\"])\n",
    "    return output_df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 1.2854,Current RMSE is 0.0591, Current R2 is 0.7995 \n",
      "Epoch: 002, Loss: 1.2661,Current RMSE is 0.0596, Current R2 is 0.7979 \n",
      "Epoch: 003, Loss: 1.2650,Current RMSE is 0.0594, Current R2 is 0.7986 \n",
      "Epoch: 004, Loss: 1.2619,Current RMSE is 0.0594, Current R2 is 0.7983 \n",
      "Epoch: 005, Loss: 1.2518,Current RMSE is 0.0596, Current R2 is 0.7979 \n",
      "Epoch: 006, Loss: 1.2443,Current RMSE is 0.0593, Current R2 is 0.7989 \n",
      "Epoch: 007, Loss: 1.2394,Current RMSE is 0.0594, Current R2 is 0.7983 \n",
      "Epoch: 008, Loss: 1.2384,Current RMSE is 0.0598, Current R2 is 0.7973 \n",
      "Epoch: 009, Loss: 1.2365,Current RMSE is 0.0597, Current R2 is 0.7974 \n",
      "Epoch: 010, Loss: 1.2338,Current RMSE is 0.0595, Current R2 is 0.7981 \n",
      "Epoch: 011, Loss: 1.2351,Current RMSE is 0.0592, Current R2 is 0.799 \n",
      "Epoch: 012, Loss: 1.2335,Current RMSE is 0.0595, Current R2 is 0.798 \n",
      "Epoch: 013, Loss: 1.2324,Current RMSE is 0.059, Current R2 is 0.7999 \n",
      "Epoch: 014, Loss: 1.2318,Current RMSE is 0.0598, Current R2 is 0.797 \n",
      "Epoch: 015, Loss: 1.2312,Current RMSE is 0.0601, Current R2 is 0.7961 \n",
      "Epoch: 016, Loss: 1.2316, Stopped on RMSE! Current RMSE is 0.0606, previous RMSE is 0.0601 \n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    # i=0\n",
    "    for batch_size, n_id, adjs in train_loader:\n",
    "        # i+=1\n",
    "        # `adjs` holds a list of `(edge_index, e_id, size)` tuples.\n",
    "        adjs = [adj.to(device) for adj in adjs]\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x[n_id].float().to(device), adjs)\n",
    "        out, pos_out, neg_out = out.split(out.size(0) // 3, dim=0)\n",
    "\n",
    "        pos_loss = F.logsigmoid((out * pos_out).sum(-1)).mean()\n",
    "        neg_loss = F.logsigmoid(-(out * neg_out).sum(-1)).mean()\n",
    "        loss = -pos_loss - neg_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * out.size(0)\n",
    "        # print(i)\n",
    "    return total_loss / number_of_nodes\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_model_embedding():\n",
    "    model.eval()\n",
    "    embedding = model.full_forward(x.float().to(device), edge_index.to(device),edge_weight.to(device)).cpu()\n",
    "    return embedding\n",
    "\n",
    "\n",
    "historical_rmse, historical_r2, historical_loss = np.inf, np.inf, np.inf\n",
    "for epoch in range(1, 80):\n",
    "    loss = train()\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        temp_embedding = model.full_forward(x.float().to(device), edge_index.to(device),edge_weight.to(device)).cpu()\n",
    "        regression_rmse, regression_r2 = regression_train(temp_embedding)\n",
    "\n",
    "        if historical_rmse == np.inf:\n",
    "            historical_rmse = regression_rmse\n",
    "\n",
    "        if historical_r2 == np.inf:\n",
    "            historical_r2 = regression_r2\n",
    "\n",
    "        if historical_loss == np.inf:\n",
    "            historical_loss = loss\n",
    "\n",
    "        if loss > historical_loss:\n",
    "            if regression_rmse > historical_rmse:\n",
    "                if epoch < 15:\n",
    "                    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f},Current RMSE is {regression_rmse}, Current R2 is {regression_r2} ')\n",
    "                    continue\n",
    "                print(\n",
    "                    f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Stopped on RMSE! Current RMSE is {regression_rmse}, previous RMSE is {historical_rmse} ')\n",
    "                break\n",
    "\n",
    "            if regression_r2 < historical_r2:\n",
    "                 if epoch < 15:\n",
    "                    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f},Current RMSE is {regression_rmse}, Current R2 is {regression_r2} ')\n",
    "                    continue\n",
    "                 print(\n",
    "                     f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Stopped on r2! Current R2 is {regression_r2}, previous R2 is {historical_r2} ')\n",
    "                 break\n",
    "        else:\n",
    "            historical_loss = loss\n",
    "            historical_rmse = regression_rmse\n",
    "            historical_r2 = regression_r2\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f},Current RMSE is {regression_rmse}, Current R2 is {regression_r2} ')\n",
    "        output_embedding = temp_embedding\n",
    "\n",
    "#output_embedding = get_model_embedding()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0288, -0.0076,  0.0523,  ..., -0.2597,  0.1444,  0.1797],\n",
      "        [ 0.0283, -0.0076,  0.0527,  ..., -0.2587,  0.1451,  0.1798],\n",
      "        [ 0.0278, -0.0073,  0.0530,  ..., -0.2596,  0.1435,  0.1799],\n",
      "        ...,\n",
      "        [ 0.0287, -0.0060,  0.0512,  ..., -0.2607,  0.1425,  0.1782],\n",
      "        [ 0.0286, -0.0060,  0.0512,  ..., -0.2607,  0.1426,  0.1782],\n",
      "        [ 0.0287, -0.0061,  0.0512,  ..., -0.2607,  0.1426,  0.1783]])\n"
     ]
    }
   ],
   "source": [
    "print(output_embedding)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akl_embedding_1670805217.csv\n"
     ]
    }
   ],
   "source": [
    "output_np = output_embedding.numpy()  #convert to Numpy array\n",
    "output_df = pd.DataFrame(output_np)  #convert to a dataframe\n",
    "current_GMT = time.gmtime()\n",
    "ts = calendar.timegm(current_GMT)\n",
    "output_df.to_csv(f\"./outputs/embeddings/prewalk/without_amenity_filters/edge_weight/akl_embedding_{ts}.csv\", index=False)  #save to file\n",
    "print(f\"akl_embedding_{ts}.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
